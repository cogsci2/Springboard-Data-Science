
We started off verifying that our resort is in the data and that we weren't missing any values.  Everything looked fine.  

Original Number of Rows: 330
Final Number of Rows: 277

We ended up dropping the fastEight column since so much data was missing and most of the data was 0 except for a single 1.

We dropped AdultWeekday after noticing it had more NaNs than AdultWeekend, so we chose to focus on the latter.  We also dropped any rows where AdultWeekend was a NaN.

We checked for duplicate resort names and found Crystal Mountain was listed twice but they were actually 2 different resorts in different regions.

We then looked at Region vs State.  Apparently they were different with some overlap where regions crossed state lines, particularly in California.

The question became - how can we use the state information to suggest the most effective price points.  

Looking at the feature distributions, we notice quite a bit of the data is skewed or has low variance.  








 Write a summary statement that highlights the key processes and findings from this notebook. 
 
 What columns, if any, have been removed? 
 Any rows? Summarise the reasons why. Were any other issues found? 
 
 What remedial actions did you take? 
 
 State where you are in the project. 
 
 Can you confirm what the target feature is for your desire to predict ticket price? 
 
 How many rows were left in the data? 